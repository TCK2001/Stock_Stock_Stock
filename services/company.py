# services/company.py
import io, re
from functools import lru_cache
from pathlib import Path

import pandas as pd
import requests  # í•„ìš” ì—†ìœ¼ë©´ ë‚˜ì¤‘ì— ì§€ì›Œë„ ë¨

LOCAL_COMPANY_FILE = (
    Path(__file__).resolve().parent.parent / "data" / "t187ap03_L.json"
    # JSONì´ ì•„ë‹ˆë¼ CSVë¡œ ì €ì¥í–ˆë‹¤ë©´ ìœ„ ì¤„ì„ ì´ë ‡ê²Œ ë°”ê¿”
    # Path(__file__).resolve().parent.parent / "data" / "t187ap03_L.csv"
)

TWSE_COMPANY_BASIC = "https://openapi.twse.com.tw/v1/opendata/t187ap03_L"
ISIN_URL = "https://isin.twse.com.tw/isin/C_public.jsp?strMode=2"


def _normalize_company_df(df: pd.DataFrame) -> pd.DataFrame:
    """ì—´ ì´ë¦„ ì •ë¦¬ + code/name ì¶”ì¶œ + 4ìë¦¬ ì½”ë“œë§Œ ë‚¨ê¸°ê¸°"""
    df = df.copy()
    df.columns = [str(c).strip() for c in df.columns]

    code_candidates = [
        c
        for c in df.columns
        if ("å…¬å¸ä»£è™Ÿ" in c)
        or ("è­‰åˆ¸ä»£è™Ÿ" in c)
        or (str(c).strip().lower() == "code")
    ]
    name_candidates = [
        c
        for c in df.columns
        if ("å…¬å¸åç¨±" in c)
        or ("è­‰åˆ¸åç¨±" in c)
        or (str(c).strip().lower() == "name")
    ]

    if not code_candidates or not name_candidates:
        raise ValueError("íšŒì‚¬ ê¸°ë³¸ìë£Œì˜ ì—´ ì´ë¦„ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    code_col = code_candidates[0]
    name_col = name_candidates[0]

    out = pd.DataFrame(
        {
            "code": df[code_col].astype(str).str.replace(".0", "", regex=False).str.strip(),
            "name": df[name_col].astype(str).str.strip(),
        }
    )

    # 4ìë¦¬ ìˆ«ì ì½”ë“œë§Œ
    out = out[out["code"].str.fullmatch(r"\d{4}")]
    out = out.drop_duplicates(subset=["code"], keep="first").reset_index(drop=True)
    return out


# ğŸ”¹ 1) "ë¡œì»¬ì— ì €ì¥í•´ ë‘” t187ap03_L íŒŒì¼"ì—ì„œ ì½ì–´ì˜¤ê¸°
def _load_company_from_local() -> pd.DataFrame:
    if not LOCAL_COMPANY_FILE.exists():
        raise FileNotFoundError(f"íšŒì‚¬ ê¸°ë³¸ìë£Œ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {LOCAL_COMPANY_FILE}")

    suffix = LOCAL_COMPANY_FILE.suffix.lower()

    if suffix == ".json":
        # TWSE openapi JSON ê·¸ëŒ€ë¡œ ì €ì¥í•œ ê²½ìš°
        df = pd.read_json(LOCAL_COMPANY_FILE)
        return _normalize_company_df(df)

    elif suffix == ".csv":
        # CSVë¡œ ì €ì¥í•œ ê²½ìš°
        df = pd.read_csv(LOCAL_COMPANY_FILE, engine="python", on_bad_lines="skip")
        return _normalize_company_df(df)

    else:
        # í˜¹ì‹œ ëª¨ë¥¼ ê²½ìš°: í™•ì¥ìì— ìƒê´€ì—†ì´ í•œ ë²ˆì”© ì‹œë„
        try:
            df = pd.read_json(LOCAL_COMPANY_FILE)
            return _normalize_company_df(df)
        except Exception:
            df = pd.read_csv(LOCAL_COMPANY_FILE, engine="python", on_bad_lines="skip")
            return _normalize_company_df(df)


# ğŸ”¹ 2) (ì„ íƒ) ì—¬ì „íˆ ì˜¨ë¼ì¸ì—ì„œ ë°›ì•„ì˜¤ëŠ” ë²„ì „ â€“ ë¡œì»¬ ì‹¤íŒ¨ ì‹œ ë°±ì—…ìš©
def _fetch_company_from_openapi() -> pd.DataFrame:
    r = requests.get(TWSE_COMPANY_BASIC, timeout=20)
    r.raise_for_status()
    txt = r.text.strip()

    # JSON ìš°ì„ 
    try:
        js = r.json()
        if isinstance(js, list) and js:
            return _normalize_company_df(pd.DataFrame(js))
    except Exception:
        pass

    # CSV ê´€ëŒ€ íŒŒì‹±
    df = pd.read_csv(io.StringIO(txt), engine="python", on_bad_lines="skip")
    return _normalize_company_df(df)


# ğŸ”¹ 3) (ì„ íƒ) ISIN ë°±ì—… â€“ í•„ìš” ì—†ìœ¼ë©´ ì™„ì „íˆ ì§€ì›Œë„ ë¨
def _fetch_company_from_isin_backup() -> pd.DataFrame:
    try:
        tables = pd.read_html(ISIN_URL)
    except Exception as e:
        print("ISIN backup fetch failed:", e)
        return pd.DataFrame(columns=["code", "name"])

    t = tables[0].copy()
    t.columns = t.iloc[0]
    t = t[1:].rename(columns=lambda x: str(x).strip())

    def split_code_name(x):
        s = str(x)
        m = re.match(r"^(\d{4})\s+(.+)$", s)
        if m:
            return m.group(1), m.group(2)
        return "", s

    t["code"], t["name"] = zip(*t["æœ‰åƒ¹è­‰åˆ¸ä»£è™ŸåŠåç¨±"].map(split_code_name))
    out = t[["code", "name"]]
    out = out[out["code"].str.fullmatch(r"\d{4}")]
    return out.drop_duplicates(subset=["code"]).reset_index(drop=True)


@lru_cache(maxsize=1)
def load_company_table() -> pd.DataFrame:
    """
    1ìˆœìœ„: ë¡œì»¬ íŒŒì¼(data/t187ap03_L.*)
    2ìˆœìœ„: TWSE openapi (ì˜¨ë¼ì¸)
    3ìˆœìœ„: ISIN ë°±ì—…
    ê·¸ë˜ë„ ë‹¤ ì‹¤íŒ¨í•˜ë©´ ë¹ˆ í…Œì´ë¸”
    """
    # 1) ë¡œì»¬ íŒŒì¼ ìš°ì„ 
    try:
        print(f"Loading company table from local file: {LOCAL_COMPANY_FILE}")
        return _load_company_from_local()
    except Exception as e0:
        print("Local company file load failed:", e0)

    # 2) ì˜¨ë¼ì¸ openapi (Streamlit Cloudì—ì„œ ë§‰í˜€ ìˆì„ ìˆ˜ë„ ìˆìŒ)
    try:
        print("Trying TWSE openapi...")
        return _fetch_company_from_openapi()
    except Exception as e1:
        print("OpenAPI fetch failed:", e1)

    # 3) ISIN ë°±ì—…
    try:
        print("Trying ISIN backup...")
        return _fetch_company_from_isin_backup()
    except Exception as e2:
        print("ISIN backup fetch failed:", e2)

    # 4) ê²°êµ­ ì „ë¶€ ì‹¤íŒ¨í•˜ë©´ ë¹ˆ í…Œì´ë¸”
    print("All sources failed. Returning empty company table.")
    return pd.DataFrame(columns=["code", "name"])


def search_code(keyword: str) -> pd.DataFrame:
    t = load_company_table()
    k = (keyword or "").strip().lower().replace("\u3000", " ")
    if t.empty:
        # íšŒì‚¬ í…Œì´ë¸” ìì²´ê°€ ë¹„ì–´ ìˆìœ¼ë©´ ë°”ë¡œ ë¹ˆ ê²°ê³¼
        return t.copy()

    m = t["name"].str.lower().str.contains(k, na=False) | t["code"].str.contains(k, na=False)
    return t[m].copy()
